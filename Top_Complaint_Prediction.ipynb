{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Top Complaint Prediction </h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h7> From the complaint analysis, it is clear that \"HEAT/ HOT WATER\" is the most severe complaint. Therefore it might be helpful to know whether it is possible to predict whether given complaint is \"HEAT/ HOT WATER\". We will use Random forest classfier for this prediction. Since total dataset might overwhelm the available computing power, we will use only 2019 data. For feature we will use \"Open Data Channel Type\", \"Borough\", and \"City\" </h7>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "body = \"NYC_311_Data_Sort_2019.csv\"\n",
    "df = pd.read_csv(body)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "##drop the unnecessary columns\n",
    "df = df[['Unique Key', 'Created Date', 'Closed Date', 'Complaint Type', 'Incident Zip',\n",
    "         'Incident Address', 'Street Name', 'City', 'Borough', 'Open Data Channel Type']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sujit\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "df['City'] = df['City'].str.upper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "def top_complaint(a):\n",
    "    b = []\n",
    "    a = list(a)\n",
    "    \n",
    "    for i in a:\n",
    "        if i == \"HEAT/HOT WATER\":\n",
    "            b.append(1)\n",
    "        else :\n",
    "            b.append(0)\n",
    "        \n",
    "    return b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier as RFC\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import mean_absolute_error as MAE\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE is: 0.38255943658275193\n",
      "Accuracy score is: 0.6174405634172481\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.93      0.72     24451\n",
      "           1       0.76      0.26      0.39     21270\n",
      "\n",
      "    accuracy                           0.62     45721\n",
      "   macro avg       0.67      0.59      0.55     45721\n",
      "weighted avg       0.67      0.62      0.57     45721\n",
      "\n"
     ]
    }
   ],
   "source": [
    "##Feature Selection\n",
    "X_dummy = pd.get_dummies(data=df[[\"Open Data Channel Type\", \"Borough\"]])\n",
    "X = X_dummy.drop(columns=[\"Open Data Channel Type_ONLINE\", \"Borough_BROOKLYN\"])\n",
    "y = pd.Series(top_complaint(df['Complaint Type']))\n",
    "\n",
    "##Train Test Split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.1, random_state = 50)\n",
    "\n",
    "##Model training and testing\n",
    "model = RFC(n_estimators=200, criterion='entropy', class_weight=\"balanced_subsample\", bootstrap=True, max_features=\"auto\")\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "##Feature Importance\n",
    "#cols = list(X.columns)\n",
    "#importance = list(model.feature_importances_)\n",
    "#feat_imp = pd.DataFrame({\"Columns\" : cols, \"feature Importance\" : importance})\n",
    "#feat_imp\n",
    "\n",
    "##Evaluation\n",
    "print(\"MAE is:\", MAE(y_test, y_pred))\n",
    "print(\"Accuracy score is:\", accuracy_score(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE is: 0.38255943658275193\n",
      "Accuracy score is: 0.6174405634172481\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.93      0.72     24451\n",
      "           1       0.76      0.26      0.39     21270\n",
      "\n",
      "    accuracy                           0.62     45721\n",
      "   macro avg       0.67      0.59      0.55     45721\n",
      "weighted avg       0.67      0.62      0.57     45721\n",
      "\n"
     ]
    }
   ],
   "source": [
    "##Feature Selection\n",
    "X_dummy = pd.get_dummies(data=df[[\"Open Data Channel Type\", \"Borough\"]])\n",
    "X = X_dummy.drop(columns=[\"Open Data Channel Type_ONLINE\", \"Borough_BRONX\"])\n",
    "y = pd.Series(top_complaint(df['Complaint Type']))\n",
    "\n",
    "##Train Test Split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.1, random_state = 50)\n",
    "\n",
    "##Model training and testing\n",
    "model = RFC(n_estimators=200, criterion='entropy', class_weight=\"balanced_subsample\", bootstrap=True, max_features=\"auto\")\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "##Feature Importance\n",
    "#cols = list(X.columns)\n",
    "#importance = list(model.feature_importances_)\n",
    "#feat_imp = pd.DataFrame({\"Columns\" : cols, \"feature Importance\" : importance})\n",
    "#feat_imp\n",
    "\n",
    "##Evaluation\n",
    "print(\"MAE is:\", MAE(y_test, y_pred))\n",
    "print(\"Accuracy score is:\", accuracy_score(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE is: 0.38255943658275193\n",
      "Accuracy score is: 0.6174405634172481\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.93      0.72     24451\n",
      "           1       0.76      0.26      0.39     21270\n",
      "\n",
      "    accuracy                           0.62     45721\n",
      "   macro avg       0.67      0.59      0.55     45721\n",
      "weighted avg       0.67      0.62      0.57     45721\n",
      "\n"
     ]
    }
   ],
   "source": [
    "##Feature Selection\n",
    "X_dummy = pd.get_dummies(data=df[[\"Open Data Channel Type\", \"Borough\"]])\n",
    "X = X_dummy.drop(columns=[\"Open Data Channel Type_ONLINE\", \"Borough_MANHATTAN\"])\n",
    "y = pd.Series(top_complaint(df['Complaint Type']))\n",
    "\n",
    "##Train Test Split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.1, random_state = 50)\n",
    "\n",
    "##Model training and testing\n",
    "model = RFC(n_estimators=200, criterion='entropy', class_weight=\"balanced_subsample\", bootstrap=True, max_features=\"auto\")\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "##Feature Importance\n",
    "#cols = list(X.columns)\n",
    "#importance = list(model.feature_importances_)\n",
    "#feat_imp = pd.DataFrame({\"Columns\" : cols, \"feature Importance\" : importance})\n",
    "#feat_imp\n",
    "\n",
    "##Evaluation\n",
    "print(\"MAE is:\", MAE(y_test, y_pred))\n",
    "print(\"Accuracy score is:\", accuracy_score(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE is: 0.38255943658275193\n",
      "Accuracy score is: 0.6174405634172481\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.93      0.72     24451\n",
      "           1       0.76      0.26      0.39     21270\n",
      "\n",
      "    accuracy                           0.62     45721\n",
      "   macro avg       0.67      0.59      0.55     45721\n",
      "weighted avg       0.67      0.62      0.57     45721\n",
      "\n"
     ]
    }
   ],
   "source": [
    "##Feature Selection\n",
    "X_dummy = pd.get_dummies(data=df[[\"Open Data Channel Type\", \"Borough\"]])\n",
    "X = X_dummy.drop(columns=[\"Open Data Channel Type_ONLINE\", \"Borough_QUEENS\"])\n",
    "y = pd.Series(top_complaint(df['Complaint Type']))\n",
    "\n",
    "##Train Test Split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.1, random_state = 50)\n",
    "\n",
    "##Model training and testing\n",
    "model = RFC(n_estimators=200, criterion='entropy', class_weight=\"balanced_subsample\", bootstrap=True, max_features=\"auto\")\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "##Feature Importance\n",
    "#cols = list(X.columns)\n",
    "#importance = list(model.feature_importances_)\n",
    "#feat_imp = pd.DataFrame({\"Columns\" : cols, \"feature Importance\" : importance})\n",
    "#feat_imp\n",
    "\n",
    "##Evaluation\n",
    "print(\"MAE is:\", MAE(y_test, y_pred))\n",
    "print(\"Accuracy score is:\", accuracy_score(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE is: 0.38255943658275193\n",
      "Accuracy score is: 0.6174405634172481\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.93      0.72     24451\n",
      "           1       0.76      0.26      0.39     21270\n",
      "\n",
      "    accuracy                           0.62     45721\n",
      "   macro avg       0.67      0.59      0.55     45721\n",
      "weighted avg       0.67      0.62      0.57     45721\n",
      "\n"
     ]
    }
   ],
   "source": [
    "##Feature Selection\n",
    "X_dummy = pd.get_dummies(data=df[[\"Open Data Channel Type\", \"Borough\"]])\n",
    "X = X_dummy.drop(columns=[\"Open Data Channel Type_ONLINE\", \"Borough_STATEN ISLAND\"])\n",
    "y = pd.Series(top_complaint(df['Complaint Type']))\n",
    "\n",
    "##Train Test Split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.1, random_state = 50)\n",
    "\n",
    "##Model training and testing\n",
    "model = RFC(n_estimators=200, criterion='entropy', class_weight=\"balanced_subsample\", bootstrap=True, max_features=\"auto\")\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "##Feature Importance\n",
    "#cols = list(X.columns)\n",
    "#importance = list(model.feature_importances_)\n",
    "#feat_imp = pd.DataFrame({\"Columns\" : cols, \"feature Importance\" : importance})\n",
    "#feat_imp\n",
    "\n",
    "##Evaluation\n",
    "print(\"MAE is:\", MAE(y_test, y_pred))\n",
    "print(\"Accuracy score is:\", accuracy_score(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE is: 0.38255943658275193\n",
      "Accuracy score is: 0.6174405634172481\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.93      0.72     24451\n",
      "           1       0.76      0.26      0.39     21270\n",
      "\n",
      "    accuracy                           0.62     45721\n",
      "   macro avg       0.67      0.59      0.55     45721\n",
      "weighted avg       0.67      0.62      0.57     45721\n",
      "\n"
     ]
    }
   ],
   "source": [
    "##Feature Selection\n",
    "X_dummy = pd.get_dummies(data=df[[\"Open Data Channel Type\", \"Borough\"]])\n",
    "X = X_dummy.drop(columns=[\"Open Data Channel Type_PHONE\", \"Borough_BROOKLYN\"])\n",
    "y = pd.Series(top_complaint(df['Complaint Type']))\n",
    "\n",
    "##Train Test Split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.1, random_state = 50)\n",
    "\n",
    "##Model training and testing\n",
    "model = RFC(n_estimators=200, criterion='entropy', class_weight=\"balanced_subsample\", bootstrap=True, max_features=\"auto\")\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "##Feature Importance\n",
    "#cols = list(X.columns)\n",
    "#importance = list(model.feature_importances_)\n",
    "#feat_imp = pd.DataFrame({\"Columns\" : cols, \"feature Importance\" : importance})\n",
    "#feat_imp\n",
    "\n",
    "##Evaluation\n",
    "print(\"MAE is:\", MAE(y_test, y_pred))\n",
    "print(\"Accuracy score is:\", accuracy_score(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE is: 0.38255943658275193\n",
      "Accuracy score is: 0.6174405634172481\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.93      0.72     24451\n",
      "           1       0.76      0.26      0.39     21270\n",
      "\n",
      "    accuracy                           0.62     45721\n",
      "   macro avg       0.67      0.59      0.55     45721\n",
      "weighted avg       0.67      0.62      0.57     45721\n",
      "\n"
     ]
    }
   ],
   "source": [
    "##Feature Selection\n",
    "X_dummy = pd.get_dummies(data=df[[\"Open Data Channel Type\", \"Borough\"]])\n",
    "X = X_dummy.drop(columns=[\"Open Data Channel Type_PHONE\", \"Borough_BRONX\"])\n",
    "y = pd.Series(top_complaint(df['Complaint Type']))\n",
    "\n",
    "##Train Test Split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.1, random_state = 50)\n",
    "\n",
    "##Model training and testing\n",
    "model = RFC(n_estimators=200, criterion='entropy', class_weight=\"balanced_subsample\", bootstrap=True, max_features=\"auto\")\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "##Feature Importance\n",
    "#cols = list(X.columns)\n",
    "#importance = list(model.feature_importances_)\n",
    "#feat_imp = pd.DataFrame({\"Columns\" : cols, \"feature Importance\" : importance})\n",
    "#feat_imp\n",
    "\n",
    "##Evaluation\n",
    "print(\"MAE is:\", MAE(y_test, y_pred))\n",
    "print(\"Accuracy score is:\", accuracy_score(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE is: 0.38255943658275193\n",
      "Accuracy score is: 0.6174405634172481\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.93      0.72     24451\n",
      "           1       0.76      0.26      0.39     21270\n",
      "\n",
      "    accuracy                           0.62     45721\n",
      "   macro avg       0.67      0.59      0.55     45721\n",
      "weighted avg       0.67      0.62      0.57     45721\n",
      "\n"
     ]
    }
   ],
   "source": [
    "##Feature Selection\n",
    "X_dummy = pd.get_dummies(data=df[[\"Open Data Channel Type\", \"Borough\"]])\n",
    "X = X_dummy.drop(columns=[\"Open Data Channel Type_PHONE\", \"Borough_MANHATTAN\"])\n",
    "y = pd.Series(top_complaint(df['Complaint Type']))\n",
    "\n",
    "##Train Test Split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.1, random_state = 50)\n",
    "\n",
    "##Model training and testing\n",
    "model = RFC(n_estimators=200, criterion='entropy', class_weight=\"balanced_subsample\", bootstrap=True, max_features=\"auto\")\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "##Feature Importance\n",
    "#cols = list(X.columns)\n",
    "#importance = list(model.feature_importances_)\n",
    "#feat_imp = pd.DataFrame({\"Columns\" : cols, \"feature Importance\" : importance})\n",
    "#feat_imp\n",
    "\n",
    "##Evaluation\n",
    "print(\"MAE is:\", MAE(y_test, y_pred))\n",
    "print(\"Accuracy score is:\", accuracy_score(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE is: 0.38255943658275193\n",
      "Accuracy score is: 0.6174405634172481\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.93      0.72     24451\n",
      "           1       0.76      0.26      0.39     21270\n",
      "\n",
      "    accuracy                           0.62     45721\n",
      "   macro avg       0.67      0.59      0.55     45721\n",
      "weighted avg       0.67      0.62      0.57     45721\n",
      "\n"
     ]
    }
   ],
   "source": [
    "##Feature Selection\n",
    "X_dummy = pd.get_dummies(data=df[[\"Open Data Channel Type\", \"Borough\"]])\n",
    "X = X_dummy.drop(columns=[\"Open Data Channel Type_PHONE\", \"Borough_QUEENS\"])\n",
    "y = pd.Series(top_complaint(df['Complaint Type']))\n",
    "\n",
    "##Train Test Split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.1, random_state = 50)\n",
    "\n",
    "##Model training and testing\n",
    "model = RFC(n_estimators=200, criterion='entropy', class_weight=\"balanced_subsample\", bootstrap=True, max_features=\"auto\")\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "##Feature Importance\n",
    "#cols = list(X.columns)\n",
    "#importance = list(model.feature_importances_)\n",
    "#feat_imp = pd.DataFrame({\"Columns\" : cols, \"feature Importance\" : importance})\n",
    "#feat_imp\n",
    "\n",
    "##Evaluation\n",
    "print(\"MAE is:\", MAE(y_test, y_pred))\n",
    "print(\"Accuracy score is:\", accuracy_score(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE is: 0.38255943658275193\n",
      "Accuracy score is: 0.6174405634172481\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.93      0.72     24451\n",
      "           1       0.76      0.26      0.39     21270\n",
      "\n",
      "    accuracy                           0.62     45721\n",
      "   macro avg       0.67      0.59      0.55     45721\n",
      "weighted avg       0.67      0.62      0.57     45721\n",
      "\n"
     ]
    }
   ],
   "source": [
    "##Feature Selection\n",
    "X_dummy = pd.get_dummies(data=df[[\"Open Data Channel Type\", \"Borough\"]])\n",
    "X = X_dummy.drop(columns=[\"Open Data Channel Type_PHONE\", \"Borough_STATEN ISLAND\"])\n",
    "y = pd.Series(top_complaint(df['Complaint Type']))\n",
    "\n",
    "##Train Test Split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.1, random_state = 50)\n",
    "\n",
    "##Model training and testing\n",
    "model = RFC(n_estimators=200, criterion='entropy', class_weight=\"balanced_subsample\", bootstrap=True, max_features=\"auto\")\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "##Feature Importance\n",
    "#cols = list(X.columns)\n",
    "#importance = list(model.feature_importances_)\n",
    "#feat_imp = pd.DataFrame({\"Columns\" : cols, \"feature Importance\" : importance})\n",
    "#feat_imp\n",
    "\n",
    "##Evaluation\n",
    "print(\"MAE is:\", MAE(y_test, y_pred))\n",
    "print(\"Accuracy score is:\", accuracy_score(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE is: 0.38255943658275193\n",
      "Accuracy score is: 0.6174405634172481\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.93      0.72     24451\n",
      "           1       0.76      0.26      0.39     21270\n",
      "\n",
      "    accuracy                           0.62     45721\n",
      "   macro avg       0.67      0.59      0.55     45721\n",
      "weighted avg       0.67      0.62      0.57     45721\n",
      "\n"
     ]
    }
   ],
   "source": [
    "##Feature Selection\n",
    "X_dummy = pd.get_dummies(data=df[[\"Open Data Channel Type\", \"Borough\"]])\n",
    "X = X_dummy.drop(columns=[\"Open Data Channel Type_MOBILE\", \"Borough_BROOKLYN\"])\n",
    "y = pd.Series(top_complaint(df['Complaint Type']))\n",
    "\n",
    "##Train Test Split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.1, random_state = 50)\n",
    "\n",
    "##Model training and testing\n",
    "model = RFC(n_estimators=200, criterion='entropy', class_weight=\"balanced_subsample\", bootstrap=True, max_features=\"auto\")\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "##Feature Importance\n",
    "#cols = list(X.columns)\n",
    "#importance = list(model.feature_importances_)\n",
    "#feat_imp = pd.DataFrame({\"Columns\" : cols, \"feature Importance\" : importance})\n",
    "#feat_imp\n",
    "\n",
    "##Evaluation\n",
    "print(\"MAE is:\", MAE(y_test, y_pred))\n",
    "print(\"Accuracy score is:\", accuracy_score(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE is: 0.38255943658275193\n",
      "Accuracy score is: 0.6174405634172481\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.93      0.72     24451\n",
      "           1       0.76      0.26      0.39     21270\n",
      "\n",
      "    accuracy                           0.62     45721\n",
      "   macro avg       0.67      0.59      0.55     45721\n",
      "weighted avg       0.67      0.62      0.57     45721\n",
      "\n"
     ]
    }
   ],
   "source": [
    "##Feature Selection\n",
    "X_dummy = pd.get_dummies(data=df[[\"Open Data Channel Type\", \"Borough\"]])\n",
    "X = X_dummy.drop(columns=[\"Open Data Channel Type_MOBILE\", \"Borough_BRONX\"])\n",
    "y = pd.Series(top_complaint(df['Complaint Type']))\n",
    "\n",
    "##Train Test Split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.1, random_state = 50)\n",
    "\n",
    "##Model training and testing\n",
    "model = RFC(n_estimators=200, criterion='entropy', class_weight=\"balanced_subsample\", bootstrap=True, max_features=\"auto\")\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "##Feature Importance\n",
    "#cols = list(X.columns)\n",
    "#importance = list(model.feature_importances_)\n",
    "#feat_imp = pd.DataFrame({\"Columns\" : cols, \"feature Importance\" : importance})\n",
    "#feat_imp\n",
    "\n",
    "##Evaluation\n",
    "print(\"MAE is:\", MAE(y_test, y_pred))\n",
    "print(\"Accuracy score is:\", accuracy_score(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE is: 0.38255943658275193\n",
      "Accuracy score is: 0.6174405634172481\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.93      0.72     24451\n",
      "           1       0.76      0.26      0.39     21270\n",
      "\n",
      "    accuracy                           0.62     45721\n",
      "   macro avg       0.67      0.59      0.55     45721\n",
      "weighted avg       0.67      0.62      0.57     45721\n",
      "\n"
     ]
    }
   ],
   "source": [
    "##Feature Selection\n",
    "X_dummy = pd.get_dummies(data=df[[\"Open Data Channel Type\", \"Borough\"]])\n",
    "X = X_dummy.drop(columns=[\"Open Data Channel Type_MOBILE\", \"Borough_MANHATTAN\"])\n",
    "y = pd.Series(top_complaint(df['Complaint Type']))\n",
    "\n",
    "##Train Test Split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.1, random_state = 50)\n",
    "\n",
    "##Model training and testing\n",
    "model = RFC(n_estimators=200, criterion='entropy', class_weight=\"balanced_subsample\", bootstrap=True, max_features=\"auto\")\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "##Feature Importance\n",
    "#cols = list(X.columns)\n",
    "#importance = list(model.feature_importances_)\n",
    "#feat_imp = pd.DataFrame({\"Columns\" : cols, \"feature Importance\" : importance})\n",
    "#feat_imp\n",
    "\n",
    "##Evaluation\n",
    "print(\"MAE is:\", MAE(y_test, y_pred))\n",
    "print(\"Accuracy score is:\", accuracy_score(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE is: 0.38255943658275193\n",
      "Accuracy score is: 0.6174405634172481\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.93      0.72     24451\n",
      "           1       0.76      0.26      0.39     21270\n",
      "\n",
      "    accuracy                           0.62     45721\n",
      "   macro avg       0.67      0.59      0.55     45721\n",
      "weighted avg       0.67      0.62      0.57     45721\n",
      "\n"
     ]
    }
   ],
   "source": [
    "##Feature Selection\n",
    "X_dummy = pd.get_dummies(data=df[[\"Open Data Channel Type\", \"Borough\"]])\n",
    "X = X_dummy.drop(columns=[\"Open Data Channel Type_MOBILE\", \"Borough_QUEENS\"])\n",
    "y = pd.Series(top_complaint(df['Complaint Type']))\n",
    "\n",
    "##Train Test Split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.1, random_state = 50)\n",
    "\n",
    "##Model training and testing\n",
    "model = RFC(n_estimators=200, criterion='entropy', class_weight=\"balanced_subsample\", bootstrap=True, max_features=\"auto\")\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "##Feature Importance\n",
    "#cols = list(X.columns)\n",
    "#importance = list(model.feature_importances_)\n",
    "#feat_imp = pd.DataFrame({\"Columns\" : cols, \"feature Importance\" : importance})\n",
    "#feat_imp\n",
    "\n",
    "##Evaluation\n",
    "print(\"MAE is:\", MAE(y_test, y_pred))\n",
    "print(\"Accuracy score is:\", accuracy_score(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE is: 0.38255943658275193\n",
      "Accuracy score is: 0.6174405634172481\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.93      0.72     24451\n",
      "           1       0.76      0.26      0.39     21270\n",
      "\n",
      "    accuracy                           0.62     45721\n",
      "   macro avg       0.67      0.59      0.55     45721\n",
      "weighted avg       0.67      0.62      0.57     45721\n",
      "\n"
     ]
    }
   ],
   "source": [
    "##Feature Selection\n",
    "X_dummy = pd.get_dummies(data=df[[\"Open Data Channel Type\", \"Borough\"]])\n",
    "X = X_dummy.drop(columns=[\"Open Data Channel Type_MOBILE\", \"Borough_STATEN ISLAND\"])\n",
    "y = pd.Series(top_complaint(df['Complaint Type']))\n",
    "\n",
    "##Train Test Split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.1, random_state = 50)\n",
    "\n",
    "##Model training and testing\n",
    "model = RFC(n_estimators=200, criterion='entropy', class_weight=\"balanced_subsample\", bootstrap=True, max_features=\"auto\")\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "##Feature Importance\n",
    "#cols = list(X.columns)\n",
    "#importance = list(model.feature_importances_)\n",
    "#feat_imp = pd.DataFrame({\"Columns\" : cols, \"feature Importance\" : importance})\n",
    "#feat_imp\n",
    "\n",
    "##Evaluation\n",
    "print(\"MAE is:\", MAE(y_test, y_pred))\n",
    "print(\"Accuracy score is:\", accuracy_score(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE is: 0.38255943658275193\n",
      "Accuracy score is: 0.6174405634172481\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.93      0.72     24451\n",
      "           1       0.76      0.26      0.39     21270\n",
      "\n",
      "    accuracy                           0.62     45721\n",
      "   macro avg       0.67      0.59      0.55     45721\n",
      "weighted avg       0.67      0.62      0.57     45721\n",
      "\n"
     ]
    }
   ],
   "source": [
    "##Feature Selection\n",
    "X_dummy = pd.get_dummies(data=df[[\"Open Data Channel Type\", \"Borough\"]])\n",
    "X = X_dummy\n",
    "y = pd.Series(top_complaint(df['Complaint Type']))\n",
    "\n",
    "##Train Test Split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.1, random_state = 50)\n",
    "\n",
    "##Model training and testing\n",
    "model = RFC(n_estimators=200, criterion='entropy', class_weight=\"balanced_subsample\", bootstrap=True, max_features=\"auto\")\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "##Feature Importance\n",
    "#cols = list(X.columns)\n",
    "#importance = list(model.feature_importances_)\n",
    "#feat_imp = pd.DataFrame({\"Columns\" : cols, \"feature Importance\" : importance})\n",
    "#feat_imp\n",
    "\n",
    "##Evaluation\n",
    "print(\"MAE is:\", MAE(y_test, y_pred))\n",
    "print(\"Accuracy score is:\", accuracy_score(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE is: 0.37969423240961486\n",
      "Accuracy score is: 0.6203057675903851\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.90      0.72     24451\n",
      "           1       0.72      0.30      0.42     21270\n",
      "\n",
      "    accuracy                           0.62     45721\n",
      "   macro avg       0.66      0.60      0.57     45721\n",
      "weighted avg       0.66      0.62      0.58     45721\n",
      "\n"
     ]
    }
   ],
   "source": [
    "##Feature Selection\n",
    "X_dummy = pd.get_dummies(data=df[[\"Open Data Channel Type\", \"City\"]])\n",
    "X = X_dummy\n",
    "y = pd.Series(top_complaint(df['Complaint Type']))\n",
    "\n",
    "##Train Test Split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.1, random_state = 50)\n",
    "\n",
    "##Model training and testing\n",
    "model = RFC(n_estimators=100, criterion='entropy', class_weight=\"balanced_subsample\", bootstrap=True, max_features=\"auto\")\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "##Feature Importance\n",
    "#cols = list(X.columns)\n",
    "#importance = list(model.feature_importances_)\n",
    "#feat_imp = pd.DataFrame({\"Columns\" : cols, \"feature Importance\" : importance})\n",
    "#feat_imp\n",
    "\n",
    "##Evaluation\n",
    "print(\"MAE is:\", MAE(y_test, y_pred))\n",
    "print(\"Accuracy score is:\", accuracy_score(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE is: 0.37969423240961486\n",
      "Accuracy score is: 0.6203057675903851\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.90      0.72     24451\n",
      "           1       0.72      0.30      0.42     21270\n",
      "\n",
      "    accuracy                           0.62     45721\n",
      "   macro avg       0.66      0.60      0.57     45721\n",
      "weighted avg       0.66      0.62      0.58     45721\n",
      "\n"
     ]
    }
   ],
   "source": [
    "##Feature Selection\n",
    "X_dummy = pd.get_dummies(data=df[[\"Open Data Channel Type\", \"City\", \"Borough\"]])\n",
    "X = X_dummy\n",
    "y = pd.Series(top_complaint(df['Complaint Type']))\n",
    "\n",
    "##Train Test Split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.1, random_state = 50)\n",
    "\n",
    "##Model training and testing\n",
    "model = RFC(n_estimators=200, criterion='entropy', class_weight=\"balanced_subsample\", bootstrap=True, max_features=\"auto\")\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "##Feature Importance\n",
    "#cols = list(X.columns)\n",
    "#importance = list(model.feature_importances_)\n",
    "#feat_imp = pd.DataFrame({\"Columns\" : cols, \"feature Importance\" : importance})\n",
    "#feat_imp\n",
    "\n",
    "##Evaluation\n",
    "print(\"MAE is:\", MAE(y_test, y_pred))\n",
    "print(\"Accuracy score is:\", accuracy_score(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
